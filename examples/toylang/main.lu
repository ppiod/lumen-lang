/*
 * A script by Pedro,
 * with contributions from Piod.
*/


use string;
use hash;

type Expression =
  | IdentifierNode(String)
  | IntLit(Integer);

type Statement =
  | VarStmt(String, Expression);

record Program(statements: Array<Statement>)

type TokenType =
  | Illegal() | Eof() | Ident(String) | Int(Integer)
  | Assign() | Semicolon() | Var();

record Token(tokenType: TokenType, literal: String)

record Lexer(
  source: String, chars: Array<String>, position: Integer,
  readPosition: Integer, ch: String
)

record Parser(
  lexer: Lexer, currentToken: Token, peekToken: Token, errors: Array<String>
)

let isLetter = fn(ch: String) -> Boolean:
  "a" <= ch && ch <= "z" || "A" <= ch && ch <= "Z" || ch == "_";

let isDigit = fn(ch: String) -> Boolean:
  "0" <= ch && ch <= "9";

let substring = fn(s: String, start: Integer, end: Integer) -> String {
  let chars = string.split(s, "");
  let loop = fn loop(i: Integer, acc: String) -> String {
    if i >= end || i >= len(chars): acc else: loop(i + 1, acc + chars[i])
  };
  if start >= end || start >= len(s): "" else: loop(start, "")
};

let newToken = fn(tokenType: TokenType, literal: String) -> Token:
    Token(tokenType, literal);

let readChar = fn(l: Lexer) -> Lexer {
  let nextChar = if l.readPosition >= len(l.chars): "\0" else: l.chars[l.readPosition];
  Lexer(l.source, l.chars, l.readPosition, l.readPosition + 1, nextChar)
};

let skipWhitespace = fn skipWhitespace(l: Lexer) -> Lexer {
    if l.ch == " " || l.ch == "\t" || l.ch == "\n" || l.ch == "\r":
        skipWhitespace(readChar(l))
    else: l
};

let readIdentifier = fn(l: Lexer) -> (String, Lexer) {
  let startPos = l.position;
  let rec_read = fn rec_read(current_l: Lexer) -> Lexer {
    if isLetter(current_l.ch): rec_read(readChar(current_l)) else: current_l
  };
  let final_l = rec_read(l);
  (substring(l.source, startPos, final_l.position), final_l)
};

let readNumber = fn(l: Lexer) -> (String, Lexer) {
  let startPos = l.position;
  let rec_read = fn rec_read(current_l: Lexer) -> Lexer {
    if isDigit(current_l.ch): rec_read(readChar(current_l)) else: current_l
  };
  let final_l = rec_read(l);
  (substring(l.source, startPos, final_l.position), final_l)
};

let newLexer = fn(input: String) -> Lexer {
  readChar(Lexer(input, string.split(input, ""), 0, 0, ""))
};

let nextToken = fn(l: Lexer) -> (Token, Lexer) {
  let currentLexer = skipWhitespace(l);
  let ch = currentLexer.ch;
  
  match ch {
    "=" => (newToken(Assign(), ch), readChar(currentLexer)),
    ";" => (newToken(Semicolon(), ch), readChar(currentLexer)),
    "\0" => (newToken(Eof(), ""), currentLexer),
    _ => {
        if isLetter(ch) {
            let (literal, new_l) = readIdentifier(currentLexer);
            let tokenType = match literal {
                "var" => Var(),
                _ => Ident(literal)
            };
            (newToken(tokenType, literal), new_l)
        } else if isDigit(ch) {
            let (literal, new_l) = readNumber(currentLexer);
            (newToken(Int(string.toInteger(literal)), literal), new_l)
        } else {
            (newToken(Illegal(), ch), readChar(currentLexer))
        }
    }
  }
};

let reverse = fn(arr: Array<Any>) -> Array<Any> {
    let loop = fn(current: Array<Any>, acc: Array<Any>) -> Array<Any> {
        match current { [] => acc, [head, ...tail] => loop(tail, prepend(head, acc)) }
    };
    loop(arr, [])
};

let advanceTokens = fn(p: Parser) -> Parser {
    let (nextTokenValue, nextLexer) = nextToken(p.lexer);
    Parser(nextLexer, p.peekToken, nextTokenValue, p.errors)
};

let parseVarStatement = fn(p: Parser) -> (Statement, Parser) {
    p
    |> advanceTokens
    |> (p_after_var) => {
        let identName = p_after_var.currentToken.literal;
        p_after_var
        |> advanceTokens
        |> advanceTokens
        |> (p_after_assign) => {
            let expr = IntLit(match p_after_assign.currentToken.tokenType { Int(v) => v, _ => 0 });
            p_after_assign
            |> advanceTokens
            |> advanceTokens
            |> (p_final) => (VarStmt(identName, expr), p_final)
        }
    }
};

let parseStatement = fn(p: Parser) -> (Statement, Parser) {
    match p.currentToken.tokenType {
        Var() => parseVarStatement(p),
        _ => (VarStmt("dummy", IntLit(0)), advanceTokens(p))
    }
};

let newParser = fn(l: Lexer) -> Parser {
    let (tok1, l1) = nextToken(l);
    let (tok2, l2) = nextToken(l1);
    Parser(l2, tok1, tok2, [])
};

let parseProgram = fn(p: Parser) -> (Program, Parser) {
    let loop = fn loop(parser_state: Parser, stmts: Array<Statement>) -> (Program, Parser) {
        match parser_state.currentToken.tokenType {
            Eof() => (Program(reverse(stmts)), parser_state),
            _ => {
                let (stmt, next_parser) = parseStatement(parser_state);
                loop(next_parser, prepend(stmt, stmts))
            }
        }
    };
    loop(p, [])
};

let newEnvironment = fn() -> Hash<String, Any>: {};

let evalExpression = fn(expr: Expression, env: Hash<String, Any>) -> Result<Any, String> {
    match expr {
        IntLit(value) => Ok(value),
        IdentifierNode(name) => match hash.get(env, name) {
            Some(value) => Ok(value),
            None() => Err(strFormat("identifier not found: {?}", name))
        }
    }
};

let evalStatement = fn(stmt: Statement, env: Hash<String, Any>) -> Result<Null, String> {
    match stmt {
        VarStmt(name, value) => {
            let evaled_value = evalExpression(value, env)?;
            hash.set(env, name, evaled_value);
            Ok(NULL)
        }
    }
};

let evalProgram = fn(prog: Program, env: Hash<String, Any>) -> Result<Null, String> {
    let evalStatements = fn evalStatements(list: Array<Statement>) -> Result<Null, String> {
        match list {
            [] => Ok(NULL),
            [head, ...tail] => {
                evalStatement(head, env)?;
                evalStatements(tail)
            }
        }
    };
    evalStatements(prog.statements)
};

let printSection = fn(title: String, content: String) {
    writeln(title);
    writeln("  " + content);
};

let main = fn() {
    let input = "var x = 10;";
    writeln("Input: '{?}'\n", input);
    
    let l_for_tokens = newLexer(input);
    let rec_print_tokens = fn rec_print_tokens(l: Lexer) -> Null {
        let (tok, next_l) = nextToken(l);
        writeln("  " + toString(tok));
        if match tok.tokenType { Eof() => true, _ => false }:
            NULL
        else:
            rec_print_tokens(next_l)
    };
    writeln("1. Tokenizing");
    rec_print_tokens(l_for_tokens);
    
    writeln("\n2. Parsing & 3. Evaluating");
    let l_for_parser = newLexer(input);
    let p = newParser(l_for_parser);
    let (program, final_parser) = parseProgram(p);

    match final_parser.errors {
        [] => {
            printSection("Parsed Program:", toString(program));
            
            let env = newEnvironment();
            match evalProgram(program, env) {
                Ok(_) => printSection("\nFinal Environment:", toString(env)),
                Err(msg) => printSection("Evaluation Error:", msg)
            }
        },
        errors => writeln("Encountered parsing errors: {?}", errors)
    }
};

main();